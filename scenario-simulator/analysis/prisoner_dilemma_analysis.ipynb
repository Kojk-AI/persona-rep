{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prisoner's Dilemma Analysis\n",
    "We will be using this file to analyze the result from prisoner's dilemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>system_prompt</th>\n",
       "      <th>llm_params</th>\n",
       "      <th>prisoner</th>\n",
       "      <th>logged_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>467a2d98-a17a-47ac-96a6-419eb6edbc05</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>84960fc4-2600-42d8-89ca-21f1fb3345f0</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>722ee6c3-1225-411c-994e-8389a8507afa</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>ebbf47ab-ca02-4431-a80f-50ea7f5cf9cc</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>98c27362-869d-4d14-8f22-fdc16251b0a1</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>3f6da7d1-92ef-4914-a39a-f0695b0e9ee0</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>e101b7f1-4020-492f-9328-ff5fadd96a17</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>29b07531-8003-405f-a46a-7289537115ba</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>fc7dd3ba-de96-4fd7-8880-619432d1eb7f</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>5d0bf5ed-67ae-402c-866b-65d867c01daf</td>\n",
       "      <td>repe-mistral-nemo</td>\n",
       "      <td>Your personality is 0% conscientiousness based...</td>\n",
       "      <td>BETRAY</td>\n",
       "      <td>You are about to play a game called the \"Priso...</td>\n",
       "      <td>{\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>2024-09-30 07:01:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       conversation_id         model_name  \\\n",
       "0          10  467a2d98-a17a-47ac-96a6-419eb6edbc05  repe-mistral-nemo   \n",
       "1          11  84960fc4-2600-42d8-89ca-21f1fb3345f0  repe-mistral-nemo   \n",
       "2          12  722ee6c3-1225-411c-994e-8389a8507afa  repe-mistral-nemo   \n",
       "3          13  ebbf47ab-ca02-4431-a80f-50ea7f5cf9cc  repe-mistral-nemo   \n",
       "4          14  98c27362-869d-4d14-8f22-fdc16251b0a1  repe-mistral-nemo   \n",
       "5          15  3f6da7d1-92ef-4914-a39a-f0695b0e9ee0  repe-mistral-nemo   \n",
       "6          16  e101b7f1-4020-492f-9328-ff5fadd96a17  repe-mistral-nemo   \n",
       "7          17  29b07531-8003-405f-a46a-7289537115ba  repe-mistral-nemo   \n",
       "8          18  fc7dd3ba-de96-4fd7-8880-619432d1eb7f  repe-mistral-nemo   \n",
       "9          19  5d0bf5ed-67ae-402c-866b-65d867c01daf  repe-mistral-nemo   \n",
       "\n",
       "                                              prompt response  \\\n",
       "0  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "1  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "2  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "3  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "4  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "5  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "6  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "7  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "8  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "9  Your personality is 0% conscientiousness based...   BETRAY   \n",
       "\n",
       "                                       system_prompt  \\\n",
       "0  You are about to play a game called the \"Priso...   \n",
       "1  You are about to play a game called the \"Priso...   \n",
       "2  You are about to play a game called the \"Priso...   \n",
       "3  You are about to play a game called the \"Priso...   \n",
       "4  You are about to play a game called the \"Priso...   \n",
       "5  You are about to play a game called the \"Priso...   \n",
       "6  You are about to play a game called the \"Priso...   \n",
       "7  You are about to play a game called the \"Priso...   \n",
       "8  You are about to play a game called the \"Priso...   \n",
       "9  You are about to play a game called the \"Priso...   \n",
       "\n",
       "                                          llm_params prisoner  \\\n",
       "0  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "1  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "2  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "3  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "4  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "5  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "6  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "7  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "8  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "9  {\"temperature\": 0.3, \"coeff\": 0.0, \"direction\"...        A   \n",
       "\n",
       "           logged_time  \n",
       "0  2024-09-30 07:01:08  \n",
       "1  2024-09-30 07:01:08  \n",
       "2  2024-09-30 07:01:08  \n",
       "3  2024-09-30 07:01:08  \n",
       "4  2024-09-30 07:01:08  \n",
       "5  2024-09-30 07:01:08  \n",
       "6  2024-09-30 07:01:09  \n",
       "7  2024-09-30 07:01:09  \n",
       "8  2024-09-30 07:01:09  \n",
       "9  2024-09-30 07:01:09  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/logs/repe-mistral-nemo/repe-mistral-nemo-conscientiousness-minus-prompting_prisoner_A_result.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataframe_results(df):\n",
    "\t\"\"\"\n",
    "\tFunction to count valid and invalid responses from a DataFrame and return various statistics.\n",
    "\n",
    "\tParameters:\n",
    "\t- df (pd.DataFrame): A DataFrame containing 'response' and 'model_name' columns.\n",
    "\n",
    "\tReturns:\n",
    "\t- dict: A dictionary containing the following statistics:\n",
    "\t\t- model_name (str): The model name (consistent across the DataFrame).\n",
    "\t\t- total_rows (int): The total number of rows (entries) in the DataFrame.\n",
    "\t\t- betray_count (int): The number of times \"betray\" appeared in the 'response' column.\n",
    "\t\t- cooperate_count (int): The number of times \"cooperate\" appeared in the 'response' column.\n",
    "\t\t- invalid_count (int): The number of invalid responses (neither \"betray\" nor \"cooperate\").\n",
    "\t\t- betray_percentage (float): The percentage of \"betray\" responses relative to total rows.\n",
    "\t\t- cooperate_percentage (float): The percentage of \"cooperate\" responses relative to total rows.\n",
    "\t\t- invalid_percentage (float): The percentage of invalid responses relative to total rows.\n",
    "\t\"\"\"\n",
    "\t# Ensure the required columns exist\n",
    "\tif df is None or 'response' not in df.columns or 'model_name' not in df.columns:\n",
    "\t\traise ValueError(\"The DataFrame must contain 'response' and 'model_name' columns.\")\n",
    "\t\n",
    "\t# Lowercase the 'response' column\n",
    "\tdf['response_lower'] = df['response'].str.lower().str.strip()\n",
    "\t\n",
    "\t# Get the model name (assuming it's consistent across the file)\n",
    "\tmodel_name = df['model_name'].iloc[0]  # Take the first value as the model name\n",
    "\tprisoner = df['prisoner'].iloc[0]\n",
    "\t\n",
    "\t# Check if each response is valid ('betray' or 'cooperate')\n",
    "\tvalid_responses = df['response_lower'].isin(['betray', 'cooperate'])\n",
    "\t\n",
    "\t# Total number of rows (runs)\n",
    "\ttotal_rows = len(df)\n",
    "\t\n",
    "\t# Count occurrences of \"betray\" and \"cooperate\"\n",
    "\tbetray_count = (df['response_lower'] == 'betray').sum()\n",
    "\tcooperate_count = (df['response_lower'] == 'cooperate').sum()\n",
    "\t\n",
    "\t# Count invalid responses (neither \"betray\" nor \"cooperate\")\n",
    "\tinvalid_count = (~valid_responses).sum()\n",
    "\t\n",
    "\t# Calculate percentages\n",
    "\tbetray_percentage = (betray_count / total_rows) * 100 if total_rows > 0 else 0\n",
    "\tcooperate_percentage = (cooperate_count / total_rows) * 100 if total_rows > 0 else 0\n",
    "\tinvalid_percentage = (invalid_count / total_rows) * 100 if total_rows > 0 else 0\n",
    "\t\n",
    "\t# Return the result as a dictionary\n",
    "\treturn {\n",
    "\t\t'model_name': model_name,\n",
    "\t\t'prisoner': prisoner,\n",
    "\t\t'total_rows': total_rows,\n",
    "\t\t'betray_count': betray_count,\n",
    "\t\t'cooperate_count': cooperate_count,\n",
    "\t\t'invalid_count': invalid_count,\n",
    "\t\t'betray_percentage': betray_percentage,\n",
    "\t\t'cooperate_percentage': cooperate_percentage,\n",
    "\t\t'invalid_percentage': invalid_percentage\n",
    "\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'repe-mistral-nemo',\n",
       " 'prisoner': 'A',\n",
       " 'total_rows': 10,\n",
       " 'betray_count': 0,\n",
       " 'cooperate_count': 10,\n",
       " 'invalid_count': 0,\n",
       " 'betray_percentage': 0.0,\n",
       " 'cooperate_percentage': 100.0,\n",
       " 'invalid_percentage': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_dataframe_results(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: vicuna\n",
      "  Prisoner A:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 0 (0.00%)\n",
      "    Cooperate Count: 0 (0.00%)\n",
      "    Invalid Count: 100 (100.00%)\n",
      "  Prisoner B:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 0 (0.00%)\n",
      "    Cooperate Count: 0 (0.00%)\n",
      "    Invalid Count: 100 (100.00%)\n",
      "----------------------------------------\n",
      "\n",
      "Model: llama2\n",
      "  Prisoner A:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 100 (100.00%)\n",
      "    Cooperate Count: 0 (0.00%)\n",
      "    Invalid Count: 0 (0.00%)\n",
      "  Prisoner B:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 100 (100.00%)\n",
      "    Cooperate Count: 0 (0.00%)\n",
      "    Invalid Count: 0 (0.00%)\n",
      "----------------------------------------\n",
      "\n",
      "Model: repe-mistral-nemo\n",
      "  Prisoner A:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 0 (0.00%)\n",
      "    Cooperate Count: 100 (100.00%)\n",
      "    Invalid Count: 0 (0.00%)\n",
      "  Prisoner B:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 0 (0.00%)\n",
      "    Cooperate Count: 100 (100.00%)\n",
      "    Invalid Count: 0 (0.00%)\n",
      "----------------------------------------\n",
      "\n",
      "Model: llama3\n",
      "  Prisoner A:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 0 (0.00%)\n",
      "    Cooperate Count: 100 (100.00%)\n",
      "    Invalid Count: 0 (0.00%)\n",
      "  Prisoner B:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 0 (0.00%)\n",
      "    Cooperate Count: 100 (100.00%)\n",
      "    Invalid Count: 0 (0.00%)\n",
      "----------------------------------------\n",
      "\n",
      "Model: mistral\n",
      "  Prisoner A:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 0 (0.00%)\n",
      "    Cooperate Count: 100 (100.00%)\n",
      "    Invalid Count: 0 (0.00%)\n",
      "  Prisoner B:\n",
      "    Total Runs: 100\n",
      "    Betray Count: 0 (0.00%)\n",
      "    Cooperate Count: 100 (100.00%)\n",
      "    Invalid Count: 0 (0.00%)\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading CSVs for different models\n",
    "llama2_prisoner_A_df = pd.read_csv('../data/logs/llama2_prisoner_A_result.csv')\n",
    "llama2_prisoner_B_df = pd.read_csv('../data/logs/llama2_prisoner_B_result.csv')\n",
    "llama3_prisoner_A_df = pd.read_csv('../data/logs/llama3_prisoner_A_result.csv')\n",
    "llama3_prisoner_B_df = pd.read_csv('../data/logs/llama3_prisoner_B_result.csv')\n",
    "mistral_prisoner_A_df = pd.read_csv('../data/logs/mistral_prisoner_A_result.csv')\n",
    "mistral_prisoner_B_df = pd.read_csv('../data/logs/mistral_prisoner_B_result.csv')\n",
    "vicuna_prisoner_A_df = pd.read_csv('../data/logs/vicuna_prisoner_A_result.csv')\n",
    "vicuna_prisoner_B_df = pd.read_csv('../data/logs/vicuna_prisoner_B_result.csv')\n",
    "repe_prisoner_A_df = pd.read_csv('../data/logs/repe-mistral-nemo-baseline_prisoner_A_result.csv')\n",
    "repe_prisoner_B_df = pd.read_csv('../data/logs/repe-mistral-nemo-baseline_prisoner_B_result.csv')\n",
    "\n",
    "# Running the analysis for each DataFrame\n",
    "llama2_prisoner_A_analysis_results = analyze_dataframe_results(llama2_prisoner_A_df)\n",
    "llama2_prisoner_B_analysis_results = analyze_dataframe_results(llama2_prisoner_B_df)\n",
    "llama3_prisoner_A_analysis_results = analyze_dataframe_results(llama3_prisoner_A_df)\n",
    "llama3_prisoner_B_analysis_results = analyze_dataframe_results(llama3_prisoner_B_df)\n",
    "mistral_prisoner_A_analysis_results = analyze_dataframe_results(mistral_prisoner_A_df)\n",
    "mistral_prisoner_B_analysis_results = analyze_dataframe_results(mistral_prisoner_B_df)\n",
    "vicuna_prisoner_A_analysis_results = analyze_dataframe_results(vicuna_prisoner_A_df)\n",
    "vicuna_prisoner_B_analysis_results = analyze_dataframe_results(vicuna_prisoner_B_df)\n",
    "repe_prisoner_A_analysis_results = analyze_dataframe_results(repe_prisoner_A_df)\n",
    "repe_prisoner_B_analysis_results = analyze_dataframe_results(repe_prisoner_B_df)\n",
    "\n",
    "# Gathering all results into a list of dictionaries for easy iteration\n",
    "all_results = [\n",
    "    llama2_prisoner_A_analysis_results,\n",
    "    llama2_prisoner_B_analysis_results,\n",
    "    llama3_prisoner_A_analysis_results,\n",
    "    llama3_prisoner_B_analysis_results,\n",
    "    mistral_prisoner_A_analysis_results,\n",
    "    mistral_prisoner_B_analysis_results,\n",
    "    vicuna_prisoner_A_analysis_results,\n",
    "    vicuna_prisoner_B_analysis_results,\n",
    "    repe_prisoner_A_analysis_results,\n",
    "    repe_prisoner_B_analysis_results,\n",
    "]\n",
    "\n",
    "# Define a function to print the results in a neat format\n",
    "def print_analysis_results(results):\n",
    "    \"\"\"\n",
    "    Function to neatly print the analysis results for all models, organized by Prisoner A and Prisoner B.\n",
    "    \"\"\"\n",
    "    # Get unique model names from the results\n",
    "    model_names = set(result['model_name'] for result in results)\n",
    "\n",
    "    for model in model_names:\n",
    "        print(f\"Model: {model}\")\n",
    "        # Filter results for the current model and for Prisoner A and B\n",
    "        prisoner_A_result = next(res for res in results if res['model_name'] == model and res['prisoner'] == 'A')\n",
    "        prisoner_B_result = next(res for res in results if res['model_name'] == model and res['prisoner'] == 'B')\n",
    "        \n",
    "        # Print results for Prisoner A\n",
    "        print(f\"  Prisoner A:\")\n",
    "        print(f\"    Total Runs: {prisoner_A_result['total_rows']}\")\n",
    "        print(f\"    Betray Count: {prisoner_A_result['betray_count']} ({prisoner_A_result['betray_percentage']:.2f}%)\")\n",
    "        print(f\"    Cooperate Count: {prisoner_A_result['cooperate_count']} ({prisoner_A_result['cooperate_percentage']:.2f}%)\")\n",
    "        print(f\"    Invalid Count: {prisoner_A_result['invalid_count']} ({prisoner_A_result['invalid_percentage']:.2f}%)\")\n",
    "        \n",
    "        # Print results for Prisoner B\n",
    "        print(f\"  Prisoner B:\")\n",
    "        print(f\"    Total Runs: {prisoner_B_result['total_rows']}\")\n",
    "        print(f\"    Betray Count: {prisoner_B_result['betray_count']} ({prisoner_B_result['betray_percentage']:.2f}%)\")\n",
    "        print(f\"    Cooperate Count: {prisoner_B_result['cooperate_count']} ({prisoner_B_result['cooperate_percentage']:.2f}%)\")\n",
    "        print(f\"    Invalid Count: {prisoner_B_result['invalid_count']} ({prisoner_B_result['invalid_percentage']:.2f}%)\")\n",
    "        print(\"-\" * 40 + '\\n')\n",
    "# Printing all results\n",
    "print_analysis_results(all_results)\n",
    "\n",
    "# <sys>\n",
    "# \n",
    "# <sys>\n",
    "# <user\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
